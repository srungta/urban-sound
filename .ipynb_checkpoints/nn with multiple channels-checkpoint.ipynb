{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up code to visualize a sound form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrung\\AppData\\Local\\Continuum\\miniconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['load', 'display']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "from librosa import load, display\n",
    "import glob\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from common import read_from_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should change these paths according to the path of the files on your system.\n",
    "PATH_TO_TRAIN_LABELS = \"data/train/train.csv\"\n",
    "PATH_TO_TEST_LABELS = \"data/test/test.csv\"\n",
    "PATH_TO_TRAIN_AUDIO_FILES = \"data/train/wav/\"\n",
    "PATH_TO_TEST_AUDIO_FILES = \"data/test/wav/\"\n",
    "PATH_TO_SUBMISSION = \"submission/\"\n",
    "PATH_TO_PICKLE = \"pickles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = read_from_pickle(PATH_TO_PICKLE + \"nn chroma train.pickle\")\n",
    "contrast = read_from_pickle(PATH_TO_PICKLE + \"nn contrast train.pickle\")\n",
    "mel =  read_from_pickle(PATH_TO_PICKLE + \"nn mel train.pickle\")\n",
    "tonnetz =  read_from_pickle(PATH_TO_PICKLE + \"nn tonnetz train.pickle\")\n",
    "mfccc =  read_from_pickle(PATH_TO_PICKLE + \"nn mfccc train.pickle\")\n",
    "\n",
    "chroma_test = read_from_pickle(PATH_TO_PICKLE + \"nn chroma test.pickle\")\n",
    "contrast_test = read_from_pickle(PATH_TO_PICKLE + \"nn contrast test.pickle\")\n",
    "mel_test =  read_from_pickle(PATH_TO_PICKLE + \"nn mel test.pickle\")\n",
    "tonnetz_test =  read_from_pickle(PATH_TO_PICKLE + \"nn tonnetz test.pickle\")\n",
    "mfccc_test =  read_from_pickle(PATH_TO_PICKLE + \"nn mfccc test.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.concat([mfccs,chroma,mel,contrast,tonnetz], axis = 1)\n",
    "test = pd.read_csv(PATH_TO_TEST_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the training feature matrix, we can apply our parser to each training sample.\n",
    "train_features = train.apply(train_parser,axis=1)\n",
    "print(\"%d samples had errors while parsing\" % train_error_count)\n",
    "print(\"Errorneous samples\", train_error_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns to singnify what they mean helps with documentation,\n",
    "# and also helps you keep track of them later on.\n",
    "train_features.columns = ['feature','label']\n",
    "# train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this library helps us convert string labels into easy to handle encoded labels.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_features.feature.tolist())\n",
    "Y = np.array(train_features.label.tolist())\n",
    "lb = LabelEncoder()\n",
    "# Since labels are categories they dont inherently have an order amongst themselves.\n",
    "# For example, Apples > oranges does not make any sense. So to madel such categorical \n",
    "# variables, we can convert them to one hot vectors.\n",
    "Y = to_categorical(lb.fit_transform(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_labels = Y.shape[1]\n",
    "filter_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(number_of_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parser(row):\n",
    "    global test_error_count\n",
    "    global test_error_labels\n",
    "    path_to_wav_files = PATH_TO_TEST_AUDIO_FILES\n",
    "    file_path = path_to_wav_files + str(row.ID) + \".wav\"\n",
    "    try:\n",
    "        data, sampling_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "        mfccs = np.mean( librosa.feature.mfcc(y = data, sr = sampling_rate, n_mfcc= 40).T, axis=0)\n",
    "    except Exception as ex:\n",
    "        test_error_count += 1\n",
    "        test_error_labels.append(row.ID)\n",
    "        return pd.Series([0]*40)\n",
    "    features = mfccs\n",
    "    return pd.Series(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "test_features = test.apply(test_parser,axis=1, reduce = True)\n",
    "print(\"%d samples had errors while parsing\" % test_error_count)\n",
    "print(\"Errorneous samples\", test_error_labels)\n",
    "#except Exception as ex:\n",
    " #   print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_features\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = model.predict(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_strings = lb.inverse_transform(test_labels.argmax(axis=1))\n",
    "# test_labels_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Class'] = test_labels_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(PATH_TO_SUBMISSION + \"sub_nn_56.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach gives 56% accuracy with the above setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
