{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up code to visualize a sound form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "from librosa import load, display\n",
    "import glob\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()\n",
    "import pickle\n",
    "from common import save_as_pickle\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should change these paths according to the path of the files on your system.\n",
    "PATH_TO_TRAIN_LABELS = \"data/train/train.csv\"\n",
    "PATH_TO_TEST_LABELS = \"data/test/test.csv\"\n",
    "PATH_TO_TRAIN_AUDIO_FILES = \"data/train/wav/\"\n",
    "PATH_TO_TEST_AUDIO_FILES = \"data/test/wav/\"\n",
    "PATH_TO_SUBMISSION = \"submission/\"\n",
    "PATH_TO_PICKLE = \"pickles/\"\n",
    "SUBMISSION_TITLE = \"nn chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is easier to deal with csv if you can load it into a structure you can work with.\n",
    "# Pandas are the most convenient way to do that and are available with \n",
    "# inbuilt functionality to handle csv file.\n",
    "\n",
    "# Pandas assumes that the first row in your file is the header adn not the actual values.\n",
    "# This behavior can be overriden by passing header=None as a parameter.\n",
    "train = pd.read_csv(PATH_TO_TRAIN_LABELS)\n",
    "test = pd.read_csv(PATH_TO_TEST_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reactivate this cell to make sure your model is working correctly in terms of dimensions.\n",
    "#train = train[:2]\n",
    "#test = test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_count = 0\n",
    "train_error_labels = []\n",
    "test_error_count = 0\n",
    "test_error_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start with classification, we first need to convert the wav sound files into a format we can work \n",
    "# with. It is easier to take the amplitude at each sampling point and use that \n",
    "# numeric value to form a feature vector.\n",
    "def train_parser(row):\n",
    "    global train_error_count\n",
    "    global train_error_labels\n",
    "    path_to_wav_files = PATH_TO_TRAIN_AUDIO_FILES\n",
    "    file_path = path_to_wav_files + str(row.ID) + \".wav\"\n",
    "    try:\n",
    "        data, sampling_rate = librosa.load(file_path)\n",
    "        stft = np.abs(librosa.stft(data))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sampling_rate).T,axis=0)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        train_error_count += 1\n",
    "        train_error_labels.append(row.ID)\n",
    "        return [0]*12, row.Class\n",
    "    features = chroma\n",
    "    label = row.Class\n",
    "    return [features, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the training feature matrix, we can apply our parser to each training sample.\n",
    "train_features = train.progress_apply(train_parser,axis=1)\n",
    "print(\"%d samples had errors while parsing\" % train_error_count)\n",
    "print(\"Errorneous samples\", train_error_labels)\n",
    "save_as_pickle(data=train_features,pickle_file=PATH_TO_PICKLE + SUBMISSION_TITLE + \" train.pickle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns to singnify what they mean helps with documentation,\n",
    "# and also helps you keep track of them later on.\n",
    "train_features.columns = ['feature','label']\n",
    "# train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this library helps us convert string labels into easy to handle encoded labels.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_features.feature.tolist())\n",
    "Y = np.array(train_features.label.tolist())\n",
    "lb = LabelEncoder()\n",
    "# Since labels are categories they dont inherently have an order amongst themselves.\n",
    "# For example, Apples > oranges does not make any sense. So to madel such categorical \n",
    "# variables, we can convert them to one hot vectors.\n",
    "Y = to_categorical(lb.fit_transform(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_labels = Y.shape[1]\n",
    "filter_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(256, input_shape=(12,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(number_of_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parser(row):\n",
    "    global test_error_count\n",
    "    global test_error_labels\n",
    "    path_to_wav_files = PATH_TO_TEST_AUDIO_FILES\n",
    "    file_path = path_to_wav_files + str(row.ID) + \".wav\"\n",
    "    try:\n",
    "        data, sampling_rate = librosa.load(file_path)\n",
    "        stft = np.abs(librosa.stft(data))\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sampling_rate).T,axis=0)\n",
    "    except Exception as ex:\n",
    "        test_error_count += 1\n",
    "        test_error_labels.append(row.ID)\n",
    "        return pd.Series([0]*12)\n",
    "    features = chroma\n",
    "    return pd.Series(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.progress_apply(test_parser,axis=1, reduce = True)\n",
    "print(\"%d samples had errors while parsing\" % test_error_count)\n",
    "print(\"Errorneous samples\", test_error_labels)\n",
    "save_as_pickle(data=test_features,pickle_file=PATH_TO_PICKLE + SUBMISSION_TITLE + \" test.pickle\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_features\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = model.predict(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_strings = lb.inverse_transform(test_labels.argmax(axis=1))\n",
    "# test_labels_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Class'] = test_labels_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(PATH_TO_SUBMISSION + SUBMISSION_TITLE + \".csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach gives 56% accuracy with the above setup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
